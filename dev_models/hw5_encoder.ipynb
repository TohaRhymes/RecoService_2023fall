{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beac72cd-78fc-4e1a-b466-6ae892d54e8a",
   "metadata": {},
   "source": [
    "# Домашка 5. NN\n",
    "\n",
    "## Autoencoder\n",
    "1. Значимо изменить архитектуру модели (2 балла)\n",
    "    * Добавил еще слои\n",
    "    * Добавил нормализацию\n",
    "    * Добавил дропаут\n",
    "2. Пробить скор бейзлайна DSSM модели 0.075. (2 балла)\n",
    "    * Побил! Скор = 0.875 \n",
    "4. Обернуть в сервис, который должен  критериям читаемости и воспоизводимости. (5 балла)\n",
    "   * обернул, запустил, тут пояснял, что происходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92954921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T15:07:30.580643869Z",
     "start_time": "2023-12-16T15:07:27.440886649Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "from random import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "from dev_eval import read_kion_dataset\n",
    "from rectools.dataset import Dataset as RecDataset\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from aerecommender import AERecommender\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57817f47-cc39-48c7-9bff-95189b3d7746",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Как всегда..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "843b139a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-16T15:07:41.434565894Z",
     "start_time": "2023-12-16T15:07:39.633995627Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv(\"../data/data_original/interactions.csv\", parse_dates=[\"last_watch_dt\"]).rename(\n",
    "    columns={\"last_watch_dt\": \"datetime\", \"total_dur\": \"weight\"}\n",
    ")\n",
    "users_df = pd.read_csv(\"../data/data_original/users.csv\")\n",
    "items_df = pd.read_csv(\"../data/data_original/items.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe9d761-0c7b-4206-b314-93abe0aed9d4",
   "metadata": {},
   "source": [
    "# Препроцессинг\n",
    "\n",
    "Удалим слишком далекие транзакции\n",
    "Оставляем пользователей с больше, чем 5 просмотрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03d4624-fc3b-4f26-84d5-30a85d5a31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df[\"datetime\"] < \"2021-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78342a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 86614\n",
      "# users with at least 5 interactions: 14563\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = interactions_df.groupby([\"user_id\", \"item_id\"]).size().groupby(\"user_id\").size()\n",
    "print(\"# users: %d\" % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[\n",
    "    [\"user_id\"]\n",
    "]\n",
    "print(\"# users with at least 5 interactions: %d\" % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd0d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 263874\n",
      "# of interactions from users with at least 5 interactions: 142670\n"
     ]
    }
   ],
   "source": [
    "print(\"# of interactions: %d\" % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(\n",
    "    users_with_enough_interactions_df, how=\"right\", left_on=\"user_id\", right_on=\"user_id\"\n",
    ")\n",
    "print(\"# of interactions from users with at least 5 interactions: %d\" % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69919ffe-cdb9-4f03-b3e1-2ecb8a0fa9c7",
   "metadata": {},
   "source": [
    "Сглаживаем признак \"время просмотра\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df43577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 142670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>849</td>\n",
       "      <td>6.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4345</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>10283</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>12261</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>15997</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>952</td>\n",
       "      <td>6.044394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>4382</td>\n",
       "      <td>4.954196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>4807</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>10436</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>12132</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  watched_pct\n",
       "0       21      849     6.375039\n",
       "1       21     4345     6.658211\n",
       "2       21    10283     6.658211\n",
       "3       21    12261     6.658211\n",
       "4       21    15997     6.658211\n",
       "5       32      952     6.044394\n",
       "6       32     4382     4.954196\n",
       "7       32     4807     6.658211\n",
       "8       32    10436     6.658211\n",
       "9       32    12132     6.658211"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1 + x, 2)\n",
    "\n",
    "\n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df.groupby([\"user_id\", \"item_id\"])[\"watched_pct\"]\n",
    "    .sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"# of unique user/item interactions: %d\" % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c6aae-6b16-4013-9578-80ab8c5d9b96",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039e1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 114136\n",
      "# interactions on Test set: 28534\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(\n",
    "    interactions_full_df, stratify=interactions_full_df[\"user_id\"], test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(\"# interactions on Train set: %d\" % len(interactions_train_df))\n",
    "print(\"# interactions on Test set: %d\" % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b38dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index(\"user_id\")\n",
    "interactions_train_indexed_df = interactions_train_df.set_index(\"user_id\")\n",
    "interactions_test_indexed_df = interactions_test_df.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb9a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id][\"item_id\"]\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a9f91-ca87-48bd-b1f5-4a7d6225f9cc",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "Создадим класс для оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03042d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df[\"item_id\"])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset[\"item_id\"]) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset[\"item_id\"])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset[\"item_id\"])])\n",
    "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(\n",
    "            person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df), topn=10000000000\n",
    "        )\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            # Getting a random sample (100) items the user has not interacted\n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(\n",
    "                person_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, seed=item_id % (2**32)\n",
    "            )\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df[\"item_id\"].isin(items_to_filter_recs)]\n",
    "            valid_recs = valid_recs_df[\"item_id\"].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items,\n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {\n",
    "            \"hits@5_count\": hits_at_5_count,\n",
    "            \"hits@10_count\": hits_at_10_count,\n",
    "            \"interacted_count\": interacted_items_count_testset,\n",
    "            \"recall@5\": recall_at_5,\n",
    "            \"recall@10\": recall_at_10,\n",
    "        }\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        # print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(tqdm(list(interactions_test_indexed_df.index.unique().values))):\n",
    "            # if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
    "            person_metrics[\"user_id\"] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print(\"%d users processed\" % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics).sort_values(\"interacted_count\", ascending=False)\n",
    "\n",
    "        global_recall_at_5 = detailed_results_df[\"hits@5_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "        global_recall_at_10 = detailed_results_df[\"hits@10_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "\n",
    "        global_metrics = {\n",
    "            \"modelName\": model.get_model_name(),\n",
    "            \"recall@5\": global_recall_at_5,\n",
    "            \"recall@10\": global_recall_at_10,\n",
    "        }\n",
    "        return global_metrics, detailed_results_df\n",
    "\n",
    "\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6f750-ecb7-4e6d-9681-c686f5f926d3",
   "metadata": {},
   "source": [
    "И саму модель\n",
    "\n",
    "__ВАЖНО__  Тут как раз улучшенная модель с дополнительными слоями, нормализацией, дропаутом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9039ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 42  # random seed for reproducibility\n",
    "LR = 1e-3  # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01  # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200  # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995  # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000  # training batch size\n",
    "EVAL_BATCH_SIZE = 3000  # evaluation batch size.\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  #'cuda' # device to make the calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5705f2b-226b-4b06-8b39-e3503d49290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features=8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size1 = 1000\n",
    "        self.hidden_size2 = 500\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_and_out_features, self.hidden_size1),\n",
    "            nn.BatchNorm1d(self.hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.hidden_size1, self.hidden_size2),\n",
    "            nn.BatchNorm1d(self.hidden_size2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size2, self.hidden_size1),\n",
    "            nn.BatchNorm1d(self.hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.hidden_size1, in_and_out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0451dc3-7915-4fb1-982b-30a2fd9dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)  # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = x_true > 0\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf20fb-b191-49ac-a62b-1ecf42a3ca04",
   "metadata": {},
   "source": [
    "# Преобразование данных в матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47f52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df[\"user_id\"], users_keys = total_df.user_id.factorize()\n",
    "total_df[\"item_id\"], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[: len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df) :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [int(total_df[\"user_id\"].max() + 1), int(total_df[\"item_id\"].max() + 1)]\n",
    "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\n",
    "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108dfd2d-0c7e-420b-81bc-64fc9574f679",
   "metadata": {},
   "source": [
    " ## Создание датасета и data loader'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89cc28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__()  # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self):  # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee1dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(UserOrientedDataset(X_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dl = DataLoader(UserOrientedDataset(X_test), batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dls = {\"train\": train_dl, \"test\": test_dl}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3aea0-900b-442e-a109-d32b76b7771a",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9cdaf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.107293</td>\n",
       "      <td>2.305213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.655865</td>\n",
       "      <td>2.304711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.344161</td>\n",
       "      <td>2.314712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.205986</td>\n",
       "      <td>2.226847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.119310</td>\n",
       "      <td>2.017134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.589207</td>\n",
       "      <td>1.247050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.589384</td>\n",
       "      <td>1.245484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.588815</td>\n",
       "      <td>1.268253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.590267</td>\n",
       "      <td>1.239051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.589815</td>\n",
       "      <td>1.250865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch  Train RMSE  Test RMSE\n",
       "0        0    2.107293   2.305213\n",
       "1        1    1.655865   2.304711\n",
       "2        2    1.344161   2.314712\n",
       "3        3    1.205986   2.226847\n",
       "4        4    1.119310   2.017134\n",
       "..     ...         ...        ...\n",
       "195    195    0.589207   1.247050\n",
       "196    196    0.589384   1.245484\n",
       "197    197    0.588815   1.268253\n",
       "198    198    0.590267   1.239051\n",
       "199    199    0.589815   1.250865\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in [\"train\", \"test\"]:\n",
    "        with torch.set_grad_enabled(stage == \"train\"):  # Whether to start building a graph for a backward pass\n",
    "            if stage == \"train\":\n",
    "                model.train()  # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval()  # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0\n",
    "            for batch in dls[stage]:\n",
    "                # batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch)  # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch)  # ¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward()  # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step()  # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()  # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1 / 2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "\n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af4996-4009-4bc8-9cb3-2a8160a59373",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "435f3f96-ac61-4012-8750-ee962a018567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0434e+00,  6.3449e+00,  4.9155e+00,  ..., -3.8341e-01,\n",
       "         -3.1926e-01,  4.9161e-01],\n",
       "        [ 2.6571e-01,  3.5488e+00,  6.9571e-01,  ..., -1.8359e-01,\n",
       "          3.0614e-02, -1.0697e-01],\n",
       "        [ 1.1215e+00,  3.9133e+00,  8.8670e-01,  ..., -1.4635e-01,\n",
       "         -1.4611e-01,  1.8826e-02],\n",
       "        ...,\n",
       "        [ 4.4887e-01,  3.6888e+00,  8.4567e-01,  ..., -2.7533e-01,\n",
       "          3.2975e-03, -3.8156e-02],\n",
       "        [ 1.6066e+00,  4.5655e+00,  1.0473e+00,  ...,  1.2819e-01,\n",
       "         -7.0163e-02, -7.1190e-02],\n",
       "        [ 1.6633e+00,  4.3546e+00,  1.1983e+00,  ..., -6.9802e-02,\n",
       "         -1.0646e-01, -2.5234e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(torch.Tensor(X_test).to(DEVICE)))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3c02f-879a-42ba-b4b2-060f99141a39",
   "metadata": {},
   "source": [
    "Готовим маппинг юзеров и лист популярного для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "777b2486-53f5-4db8-84c7-7051e5f83d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2uid = {user: id for id, user in enumerate(interactions_full_indexed_df.index.unique().tolist())}\n",
    "\n",
    "name_popular = \"../models/pickle_data/popular.pickle\"\n",
    "loaded_popular = pickle.load(open(name_popular, \"rb\"))\n",
    "data_for_predict = RecDataset.construct(interactions_df)\n",
    "max_k = len(items_df[\"item_id\"].unique())\n",
    "sample_popular_user = data_for_predict.user_id_map.external_ids[0]\n",
    "popular_list = list(\n",
    "    loaded_popular.recommend(dataset=data_for_predict, users=[0], k=max_k, filter_viewed=False)[\"item_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81340bdb-35f1-43f1-95a8-01618b6ab796",
   "metadata": {},
   "source": [
    "Теперь можно все сохранять в класс-обертку (она не сильно отличается от той, что была на лекции, но я добавил функцию для предсказания, чтобы использовать на проде) (`aerecommender.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d2929c4-9375-45e7-aadf-29c408fa15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_recommender_model = AERecommender(X_pred, X_train, X_train, user_id2uid, popular_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4d846334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@5': 0.6427491784255025, 'recall@10': 0.75609232839576}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c1b0e-8690-4102-b4e3-a860aceef04a",
   "metadata": {},
   "source": [
    "## Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "928649e5-ec71-477d-80b3-1fe8c8fb0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ae = \"../models/pickle_data/ae.pickle\"\n",
    "pickle.dump(ae_recommender_model, open(name_ae, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb53db3-400d-4d84-915c-8e275df41fff",
   "metadata": {},
   "source": [
    "# Для продакшна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60fa3d62-3c1e-464b-b2a3-1c46241983e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ae = \"../models/pickle_data/ae.pickle\"\n",
    "ae_loaded = pickle.load(open(name_ae, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e2b607f-0841-43ad-afc5-90fb2b8ce80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.1 ms ± 3.91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ae_loaded.recommend(21, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fa84c-5691-4c38-b1f5-3df928d4e158",
   "metadata": {},
   "source": [
    "Не знаю, прокатит ли, проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd17545-afbb-4c23-b3e1-a4c95384da00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
