{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6904f501-efae-4711-927f-8464f9398d31",
   "metadata": {},
   "source": [
    "# Домашка 5. NN\n",
    "\n",
    "## DSSM\n",
    "1. Использовать информацию о качестве взаимодействия юзеров с айтемами для более репрезентативного сэмплирования. (3 балла):\n",
    "    * вместо единички добавляем к матрице взаимодействий `watched_pct`\n",
    "2. Добавить текстовые признаки в модель (3 балла):\n",
    "    * Для списков режиссеров, стран -- добавил умный one-hot encoding (сплит по запятой)\n",
    "    * Для опиcаний - ruBERT использовал.\n",
    "3. Пробить скор бейзлайна DSSM модели 0.075. (2 балла)\n",
    "   * Побил: 0.086\n",
    "4. Обернуть в сервис, который должен  критериям читаемости и воспроизводимости. (5 балла)\n",
    "   * Обернул (и через бота проверку прошел):\n",
    "   * Класс модели: `dev_models/dssmmodel.py`\n",
    "   * Класс для чтения в продакшне: `models/DSSM.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T19:21:20.007715793Z",
     "start_time": "2023-11-26T19:21:18.291226287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 15:28:07.353870: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-16 15:28:07.360352: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 15:28:07.429880: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 15:28:07.430653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 15:28:08.057665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from dssmmodel import DSSMModel\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from random import randint\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from rectools.dataset import Dataset\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ED\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from dev_eval import read_kion_dataset\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1770154f8fff68e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data\n",
    "\n",
    "Подгружаем датасет кион используя дополнительную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47c6f292beddd7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T19:21:23.266476870Z",
     "start_time": "2023-11-26T19:21:20.873001451Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kion_data = read_kion_dataset(fast_check=1)\n",
    "interactions = kion_data[\"interactions\"]\n",
    "users = kion_data[\"users\"]\n",
    "items = kion_data[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a868874b-45d7-4f31-b726-dddef50e37ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime   weight  watched_pct\n",
       "0   176549     9506 2021-05-11   4250.0         72.0\n",
       "1   699317     1659 2021-05-29   8317.0        100.0\n",
       "2   656683     7107 2021-05-09     10.0          0.0\n",
       "3   864613     7638 2021-07-05  14483.0        100.0\n",
       "4   964868     9506 2021-04-30   6725.0        100.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded60ca-845e-436e-a384-04baae84a946",
   "metadata": {},
   "source": [
    "## Препроцессинг фичей айтемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce62c8c-9ec4-4aa4-9cbc-d89d543aa8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>title_orig</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>film</td>\n",
       "      <td>Поговори с ней</td>\n",
       "      <td>Hable con ella</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>драмы, зарубежные, детективы, мелодрамы</td>\n",
       "      <td>Испания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Педро Альмодовар</td>\n",
       "      <td>Адольфо Фернандес, Ана Фернандес, Дарио Гранди...</td>\n",
       "      <td>Мелодрама легендарного Педро Альмодовара «Пого...</td>\n",
       "      <td>Поговори, ней, 2002, Испания, друзья, любовь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>film</td>\n",
       "      <td>Голые перцы</td>\n",
       "      <td>Search Party</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>зарубежные, приключения, комедии</td>\n",
       "      <td>США</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Скот Армстронг</td>\n",
       "      <td>Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...</td>\n",
       "      <td>Уморительная современная комедия на популярную...</td>\n",
       "      <td>Голые, перцы, 2014, США, друзья, свадьбы, прео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>film</td>\n",
       "      <td>Тактическая сила</td>\n",
       "      <td>Tactical Force</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>криминал, зарубежные, триллеры, боевики, комедии</td>\n",
       "      <td>Канада</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Адам П. Калтраро</td>\n",
       "      <td>Адриан Холмс, Даррен Шалави, Джерри Вассерман,...</td>\n",
       "      <td>Профессиональный рестлер Стив Остин («Все или ...</td>\n",
       "      <td>Тактическая, сила, 2011, Канада, бандиты, ганг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id content_type             title      title_orig  release_year  \\\n",
       "0    10711         film    Поговори с ней  Hable con ella        2002.0   \n",
       "1     2508         film       Голые перцы    Search Party        2014.0   \n",
       "2    10716         film  Тактическая сила  Tactical Force        2011.0   \n",
       "\n",
       "                                             genres countries  for_kids  \\\n",
       "0           драмы, зарубежные, детективы, мелодрамы   Испания       NaN   \n",
       "1                  зарубежные, приключения, комедии       США       NaN   \n",
       "2  криминал, зарубежные, триллеры, боевики, комедии    Канада       NaN   \n",
       "\n",
       "   age_rating studios         directors  \\\n",
       "0        16.0     NaN  Педро Альмодовар   \n",
       "1        16.0     NaN    Скот Армстронг   \n",
       "2        16.0     NaN  Адам П. Калтраро   \n",
       "\n",
       "                                              actors  \\\n",
       "0  Адольфо Фернандес, Ана Фернандес, Дарио Гранди...   \n",
       "1  Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...   \n",
       "2  Адриан Холмс, Даррен Шалави, Джерри Вассерман,...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Мелодрама легендарного Педро Альмодовара «Пого...   \n",
       "1  Уморительная современная комедия на популярную...   \n",
       "2  Профессиональный рестлер Стив Остин («Все или ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Поговори, ней, 2002, Испания, друзья, любовь, ...  \n",
       "1  Голые, перцы, 2014, США, друзья, свадьбы, прео...  \n",
       "2  Тактическая, сила, 2011, Канада, бандиты, ганг...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d721a76-d1ff-47f8-8a66-d05e6c4099d8",
   "metadata": {},
   "source": [
    "Работаем 3 способами с фичами:\n",
    "* просто категориальные -- one hot encoding (как в лекции)\n",
    "* Раньше (в лекции) директоры и страны были в категориальных фичах, но это не совсем так, так как там через запятую могут стоять несколько категорий (например, `США, Испания`, `США`,  `Испания` были 3 разными классами, хотя это можно уместить в два класса: просто ставить единички больше чем в 1 классе). Это сделаем для `['countries', 'directors', 'genres', 'keywords']`\n",
    "* заюзаем берт для энкодинга descriptions и keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9122625-6897-4b33-9947-479cb56931b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type_film</th>\n",
       "      <th>content_type_series</th>\n",
       "      <th>for_kids_0.0</th>\n",
       "      <th>for_kids_1.0</th>\n",
       "      <th>age_rating_0.0</th>\n",
       "      <th>age_rating_6.0</th>\n",
       "      <th>age_rating_12.0</th>\n",
       "      <th>age_rating_16.0</th>\n",
       "      <th>age_rating_18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>genres_фильмы</th>\n",
       "      <th>genres_фильмы hbo</th>\n",
       "      <th>genres_фильмы-спектакли</th>\n",
       "      <th>genres_фитнес</th>\n",
       "      <th>genres_футбол</th>\n",
       "      <th>genres_фэнтези</th>\n",
       "      <th>genres_хочу всё знать</th>\n",
       "      <th>genres_шоу</th>\n",
       "      <th>genres_экранизации</th>\n",
       "      <th>genres_юмор</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7868</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  content_type_film  content_type_series  for_kids_0.0  \\\n",
       "0    10711                  1                    0             0   \n",
       "1     2508                  1                    0             0   \n",
       "2    10716                  1                    0             0   \n",
       "3     7868                  1                    0             0   \n",
       "4    16268                  1                    0             0   \n",
       "\n",
       "   for_kids_1.0  age_rating_0.0  age_rating_6.0  age_rating_12.0  \\\n",
       "0             0               0               0                0   \n",
       "1             0               0               0                0   \n",
       "2             0               0               0                0   \n",
       "3             0               0               0                0   \n",
       "4             0               0               0                1   \n",
       "\n",
       "   age_rating_16.0  age_rating_18.0  ...  genres_фильмы  genres_фильмы hbo  \\\n",
       "0                1                0  ...              0                  0   \n",
       "1                1                0  ...              0                  0   \n",
       "2                1                0  ...              0                  0   \n",
       "3                1                0  ...              0                  0   \n",
       "4                0                0  ...              0                  0   \n",
       "\n",
       "   genres_фильмы-спектакли  genres_фитнес  genres_футбол  genres_фэнтези  \\\n",
       "0                        0              0              0               0   \n",
       "1                        0              0              0               0   \n",
       "2                        0              0              0               0   \n",
       "3                        0              0              0               0   \n",
       "4                        0              0              0               0   \n",
       "\n",
       "   genres_хочу всё знать  genres_шоу  genres_экранизации  genres_юмор  \n",
       "0                      0           0                   0            0  \n",
       "1                      0           0                   0            0  \n",
       "2                      0           0                   0            0  \n",
       "3                      0           0                   0            0  \n",
       "4                      0           0                   0            0  \n",
       "\n",
       "[5 rows x 9074 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## просто one hot encoding\n",
    "item_cat_feats = [\"content_type\", \"for_kids\", \"age_rating\", \"studios\"]\n",
    "items_ohe_df = items.item_id\n",
    "\n",
    "for feat in item_cat_feats:\n",
    "    ohe_feat = pd.get_dummies(items[feat], prefix=feat)\n",
    "    items_ohe_df = pd.concat([items_ohe_df, ohe_feat], axis=1)\n",
    "\n",
    "## one hot encoding для фичей через запятую\n",
    "comma_cat_feats = [\"countries\", \"directors\", \"genres\"]\n",
    "\n",
    "for feat in comma_cat_feats:\n",
    "    ohe_feat = items[feat].str.get_dummies(sep=\", \").add_prefix(f\"{feat}_\")\n",
    "    items_ohe_df = pd.concat([items_ohe_df, ohe_feat], axis=1)\n",
    "\n",
    "items_ohe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c42e16-f9e4-474f-ac36-f2e07dd3f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем берт\n",
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "\n",
    "\n",
    "def encode_description(review):\n",
    "    encoded_review = tokenizer(review, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_review)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.numpy()[0]\n",
    "\n",
    "\n",
    "## пришлось отдельно на коллабе запустить берт и сохранить (на компе валилось)\n",
    "embedding_description = items.description.fillna(\"\").progress_apply(lambda x: encode_description(x))\n",
    "embeddings = pd.DataFrame([list(i) for i in embedding_description.to_list()])\n",
    "embeddings.to_csv(\"embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f85334b1-9a21-4e0f-8896-888f339ece79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type_film</th>\n",
       "      <th>content_type_series</th>\n",
       "      <th>for_kids_0.0</th>\n",
       "      <th>for_kids_1.0</th>\n",
       "      <th>age_rating_0.0</th>\n",
       "      <th>age_rating_6.0</th>\n",
       "      <th>age_rating_12.0</th>\n",
       "      <th>age_rating_16.0</th>\n",
       "      <th>age_rating_18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_758</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135498</td>\n",
       "      <td>-0.050018</td>\n",
       "      <td>-0.064492</td>\n",
       "      <td>-0.170823</td>\n",
       "      <td>0.039486</td>\n",
       "      <td>0.099307</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.106805</td>\n",
       "      <td>-0.135492</td>\n",
       "      <td>-0.241274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071463</td>\n",
       "      <td>0.092410</td>\n",
       "      <td>-0.030258</td>\n",
       "      <td>-0.044130</td>\n",
       "      <td>-0.108914</td>\n",
       "      <td>0.071249</td>\n",
       "      <td>0.086019</td>\n",
       "      <td>0.237594</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>0.009551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035445</td>\n",
       "      <td>-0.028603</td>\n",
       "      <td>-0.054121</td>\n",
       "      <td>-0.195034</td>\n",
       "      <td>-0.008158</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>0.035486</td>\n",
       "      <td>0.225539</td>\n",
       "      <td>-0.102949</td>\n",
       "      <td>-0.111427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7868</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037582</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.215980</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>-0.111757</td>\n",
       "      <td>0.168911</td>\n",
       "      <td>0.061653</td>\n",
       "      <td>0.165149</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>-0.256809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281592</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.104811</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>0.125230</td>\n",
       "      <td>-0.017858</td>\n",
       "      <td>-0.121802</td>\n",
       "      <td>-0.375776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9842 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  content_type_film  content_type_series  for_kids_0.0  \\\n",
       "0    10711                  1                    0             0   \n",
       "1     2508                  1                    0             0   \n",
       "2    10716                  1                    0             0   \n",
       "3     7868                  1                    0             0   \n",
       "4    16268                  1                    0             0   \n",
       "\n",
       "   for_kids_1.0  age_rating_0.0  age_rating_6.0  age_rating_12.0  \\\n",
       "0             0               0               0                0   \n",
       "1             0               0               0                0   \n",
       "2             0               0               0                0   \n",
       "3             0               0               0                0   \n",
       "4             0               0               0                1   \n",
       "\n",
       "   age_rating_16.0  age_rating_18.0  ...   emb_758   emb_759   emb_760  \\\n",
       "0                1                0  ...  0.135498 -0.050018 -0.064492   \n",
       "1                1                0  ...  0.071463  0.092410 -0.030258   \n",
       "2                1                0  ... -0.035445 -0.028603 -0.054121   \n",
       "3                1                0  ...  0.037582 -0.009220 -0.215980   \n",
       "4                0                0  ...  0.281592  0.026697  0.104811   \n",
       "\n",
       "    emb_761   emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \n",
       "0 -0.170823  0.039486  0.099307  0.054217  0.106805 -0.135492 -0.241274  \n",
       "1 -0.044130 -0.108914  0.071249  0.086019  0.237594 -0.150463  0.009551  \n",
       "2 -0.195034 -0.008158  0.033368  0.035486  0.225539 -0.102949 -0.111427  \n",
       "3  0.006530 -0.111757  0.168911  0.061653  0.165149 -0.002899 -0.256809  \n",
       "4 -0.012988  0.019750  0.234832  0.125230 -0.017858 -0.121802 -0.375776  \n",
       "\n",
       "[5 rows x 9842 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read\n",
    "embeddings = pd.read_csv(\"../data/embeddings.csv\").add_prefix(f\"emb_\")\n",
    "embeddings\n",
    "## MERGE with _df\n",
    "items_ohe_df = pd.concat([items_ohe_df, embeddings], axis=1)\n",
    "items_ohe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810cd09-4680-495b-bf05-eae5279150c6",
   "metadata": {},
   "source": [
    "## Юзеры\n",
    "\n",
    "Категориальные признаки (все) one-hot encod'им."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf9a4a2-8f38-45c8-918b-322324bf4ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_age_18_24</th>\n",
       "      <th>age_age_25_34</th>\n",
       "      <th>age_age_35_44</th>\n",
       "      <th>age_age_45_54</th>\n",
       "      <th>age_age_55_64</th>\n",
       "      <th>age_age_65_inf</th>\n",
       "      <th>income_income_0_20</th>\n",
       "      <th>income_income_150_inf</th>\n",
       "      <th>income_income_20_40</th>\n",
       "      <th>income_income_40_60</th>\n",
       "      <th>income_income_60_90</th>\n",
       "      <th>income_income_90_150</th>\n",
       "      <th>sex_Ж</th>\n",
       "      <th>sex_М</th>\n",
       "      <th>kids_flg_0</th>\n",
       "      <th>kids_flg_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age_age_18_24  age_age_25_34  age_age_35_44  age_age_45_54  \\\n",
       "0   973171              0              1              0              0   \n",
       "1   962099              1              0              0              0   \n",
       "2  1047345              0              0              0              1   \n",
       "3   721985              0              0              0              1   \n",
       "4   704055              0              0              1              0   \n",
       "\n",
       "   age_age_55_64  age_age_65_inf  income_income_0_20  income_income_150_inf  \\\n",
       "0              0               0                   0                      0   \n",
       "1              0               0                   0                      0   \n",
       "2              0               0                   0                      0   \n",
       "3              0               0                   0                      0   \n",
       "4              0               0                   0                      0   \n",
       "\n",
       "   income_income_20_40  income_income_40_60  income_income_60_90  \\\n",
       "0                    0                    0                    1   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    0                    0                    1   \n",
       "\n",
       "   income_income_90_150  sex_Ж  sex_М  kids_flg_0  kids_flg_1  \n",
       "0                     0      0      1           0           1  \n",
       "1                     0      0      1           1           0  \n",
       "2                     0      1      0           1           0  \n",
       "3                     0      1      0           1           0  \n",
       "4                     0      1      0           1           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cat_feats = [\"age\", \"income\", \"sex\", \"kids_flg\"]\n",
    "# из исходного датафрейма оставим только item_id - этот признак нам понадобится позже\n",
    "# для того, чтобы маппить айтемы из датафрейма с фильмами с айтемами\n",
    "# из датафрейма с взаимодействиями\n",
    "users_ohe_df = users.user_id\n",
    "for feat in user_cat_feats:\n",
    "    # получаем датафрейм с one-hot encoding для каждой категориальной фичи\n",
    "    ohe_feat_df = pd.get_dummies(users[feat], prefix=feat)\n",
    "    # конкатенируем ohe-hot датафрейм с датафреймом,\n",
    "    # который мы получили на предыдущем шаге\n",
    "    users_ohe_df = pd.concat([users_ohe_df, ohe_feat_df], axis=1)\n",
    "\n",
    "users_ohe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348da72e-f005-445f-95b2-3d6eb34a34da",
   "metadata": {},
   "source": [
    "## Матица взаимодействий\n",
    "\n",
    "В датасете взаимодействий есть непопулярные фильмы и малоактивные пользователи. Кроме того, в таблице взаимодействий есть события с низким качеством взаимодействия - когда юзер начал смотреть фильм, но вскоре после начала просмотра выключил.\n",
    "\n",
    "Давайте отфильтруем такие события: малоактивных юзеров и непопулярные фильмы.\n",
    "\n",
    "Тут все, как и на паре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68521758-2321-48cc-8c84-b05764b11a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N users before: 962179\n",
      "N items before: 15706\n",
      "\n",
      "N users after: 79515\n",
      "N items after: 6901\n"
     ]
    }
   ],
   "source": [
    "print(f\"N users before: {interactions.df.user_id.nunique()}\")\n",
    "print(f\"N items before: {interactions.df.item_id.nunique()}\\n\")\n",
    "\n",
    "# отфильтруем все события взаимодействий, в которых пользователь посмотрел\n",
    "# фильм менее чем на 10 процентов\n",
    "interactions_df = interactions.df[interactions.df.watched_pct > 10]\n",
    "\n",
    "# соберем всех пользователей, которые посмотрели\n",
    "# больше 10 фильмов\n",
    "valid_users = []\n",
    "\n",
    "c = Counter(interactions_df.user_id)\n",
    "for user_id, entries in c.most_common():\n",
    "    if entries > 10:\n",
    "        valid_users.append(user_id)\n",
    "\n",
    "# и соберем все фильмы, которые посмотрели больше 10 пользователей\n",
    "valid_items = []\n",
    "\n",
    "c = Counter(interactions_df.item_id)\n",
    "for item_id, entries in c.most_common():\n",
    "    if entries > 10:\n",
    "        valid_items.append(item_id)\n",
    "\n",
    "# отбросим непопулярные фильмы и неактивных юзеров\n",
    "interactions_df = interactions_df[interactions_df.user_id.isin(valid_users)]\n",
    "interactions_df = interactions_df[interactions_df.item_id.isin(valid_items)]\n",
    "\n",
    "print(f\"N users after: {interactions_df.user_id.nunique()}\")\n",
    "print(f\"N items after: {interactions_df.item_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a3af1-b6cb-4c02-a580-ed9010038701",
   "metadata": {},
   "source": [
    "После фильтрации может получиться так, что некоторые айтемы/юзеры есть в датасете взаимодействий, но при этом они отсутствуют в датасетах айтемов/юзеров или наоборот. Поэтому найдем id айтемов и id юзеров, которые есть во всех датасетах и оставим только их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7151146-9468-415e-ab6c-68eae5d138c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6897 6897\n",
      "65974 65974\n"
     ]
    }
   ],
   "source": [
    "common_users = set(interactions_df.user_id) & set(users_ohe_df.user_id)\n",
    "common_items = set(interactions_df.item_id) & set(items_ohe_df.item_id)\n",
    "\n",
    "interactions_df = interactions_df[interactions_df.item_id.isin(common_items)]\n",
    "interactions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n",
    "\n",
    "items_ohe_df = items_ohe_df[items_ohe_df.item_id.isin(common_items)]\n",
    "users_ohe_df = users_ohe_df[users_ohe_df.user_id.isin(common_users)]\n",
    "\n",
    "print(len(interactions_df.item_id.unique()), items_ohe_df.shape[0])\n",
    "print(len(interactions_df.user_id.unique()), users_ohe_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19489ccb-105d-4dd6-91bd-531100b5b078",
   "metadata": {},
   "source": [
    "Соберем взаимодействия в матрицу user*item так, чтобы в строках этой матрицы были user_id, в столбцах - item_id, а на пересечениях строк и столбцов - единица, если пользователь взаимодействовал с айтемом и ноль, если нет.\n",
    "\n",
    "Такую матрицу удобно собирать в numpy array, однако нужно помнить, что numpy array индексируется порядковыми индексами, а нам же удобнее использовать item_id и user_id.\n",
    "\n",
    "Создадим некие внутренние индексы для user_id и item_id - uid и iid. Для этого просто соберем все user_id и item_id и пронумеруем их по порядку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acee243a-f7f5-4fb8-9050-622b308cb6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "      <th>watched_pct</th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10616</td>\n",
       "      <td>3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42131</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1016458</td>\n",
       "      <td>354</td>\n",
       "      <td>2021-08-14</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61024</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>884009</td>\n",
       "      <td>693</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>703.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53150</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5324</td>\n",
       "      <td>8437</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>6598.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>310</td>\n",
       "      <td>3485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id   datetime  weight  watched_pct    uid   iid\n",
       "0    176549     9506 2021-05-11  4250.0         72.0  10616  3944\n",
       "1    699317     1659 2021-05-29  8317.0        100.0  42131   675\n",
       "6   1016458      354 2021-08-14  1672.0         25.0  61024   139\n",
       "7    884009      693 2021-08-04   703.0         14.0  53150   279\n",
       "14     5324     8437 2021-04-18  6598.0         92.0    310  3485"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df[\"uid\"] = interactions_df[\"user_id\"].astype(\"category\")\n",
    "interactions_df[\"uid\"] = interactions_df[\"uid\"].cat.codes\n",
    "\n",
    "interactions_df[\"iid\"] = interactions_df[\"item_id\"].astype(\"category\")\n",
    "interactions_df[\"iid\"] = interactions_df[\"iid\"].cat.codes\n",
    "\n",
    "print(sorted(interactions_df.iid.unique())[:5])\n",
    "print(sorted(interactions_df.uid.unique())[:5])\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379818b-a63e-4555-a3c2-161d098c4d88",
   "metadata": {},
   "source": [
    "Отнормируем матрицу взаимодействий\n",
    "\n",
    "\n",
    "__NOTE__ Тут мы выполняем 1 из куска задания: Используем информацию о проценте просмотра айтема, а не просто единичку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41941ff4-8e66-49c3-b8ce-4e358a74b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_vec = np.zeros((interactions_df.uid.nunique(), interactions_df.iid.nunique()))\n",
    "\n",
    "# Используем информацию о качестве (проценте просмотра) взаимодействия юзеров с айтемами\n",
    "# ЭТО КУСОК ЗАДАНИЯ\n",
    "for user_id, item_id, weight in zip(interactions_df.uid, interactions_df.iid, interactions_df.watched_pct):\n",
    "    interactions_vec[user_id, item_id] += weight / 100\n",
    "\n",
    "\n",
    "res = interactions_vec.sum(axis=1)\n",
    "for i in range(len(interactions_vec)):\n",
    "    interactions_vec[i] /= res[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ecc0ff3-64e5-48c4-97a2-eaa1f3767a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6897\n",
      "6897\n",
      "65974\n",
      "65974\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(interactions_df.item_id.nunique())\n",
    "print(items_ohe_df.item_id.nunique())\n",
    "print(interactions_df.user_id.nunique())\n",
    "print(users_ohe_df.user_id.nunique())\n",
    "\n",
    "print(set(items_ohe_df.item_id.unique()) - set(interactions_df.item_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7991309-4da5-440b-b88c-0e4590b241cb",
   "metadata": {},
   "source": [
    "Для того, чтобы можно было удобно превратить iid/uid в item_id/user_id и наоборот соберем словари\n",
    "\n",
    "```\n",
    "{iid: item_id}, {uid: user_id} и {item_id: iid}, {user_id: uid}.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acde0cb0-b92d-4eea-a6d9-62108ee4468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_to_item_id = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"iid\").to_dict()[\"item_id\"]\n",
    "item_id_to_iid = interactions_df[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"item_id\").to_dict()[\"iid\"]\n",
    "\n",
    "uid_to_user_id = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"uid\").to_dict()[\"user_id\"]\n",
    "user_id_to_uid = interactions_df[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"user_id\").to_dict()[\"uid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0945db6-7d67-4e94-90b6-808da6c8cd11",
   "metadata": {},
   "source": [
    "И проиндексируем датасеты users_ohe_df и items_ohe_df по внутренним айди:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8177c4d-b9c1-4a24-ac2c-c13dd5362143",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ohe_df[\"iid\"] = items_ohe_df[\"item_id\"].apply(lambda x: item_id_to_iid[x])\n",
    "items_ohe_df = items_ohe_df.set_index(\"iid\")\n",
    "\n",
    "users_ohe_df[\"uid\"] = users_ohe_df[\"user_id\"].apply(lambda x: user_id_to_uid[x])\n",
    "users_ohe_df = users_ohe_df.set_index(\"uid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661f975-2a51-48ed-a3b2-48fd1e23b5df",
   "metadata": {},
   "source": [
    "# Обучение\n",
    "\n",
    "Начинаем с лосса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b0180cf-2b0f-4332-a0b3-6a3bf100695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, n_dims=128, alpha=0.4):\n",
    "    # будем ожидать, что на вход функции прилетит три сконкатенированных\n",
    "    # вектора - вектор юзера и два вектора айтема\n",
    "    anchor = y_pred[:, 0:n_dims]\n",
    "    positive = y_pred[:, n_dims : n_dims * 2]\n",
    "    negative = y_pred[:, n_dims * 2 : n_dims * 3]\n",
    "\n",
    "    # считаем расстояния от вектора юзера до вектора хорошего айтема\n",
    "    pos_dist = K.sum(K.square(anchor - positive), axis=1)\n",
    "    # и до плохого\n",
    "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "\n",
    "    # считаем лосс\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = K.maximum(basic_loss, 0.0)  # возвращаем ноль, если лосс отрицательный\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3ceed-0736-4754-8d62-b8d90e6c8b05",
   "metadata": {},
   "source": [
    "Сделаем простой генератор. Он будет брать рандромного юзера, и два разных айтема - хороший пример и плохой:\n",
    "\n",
    "хорошим примером будет тот айтем, который был взят из датасета взаимодействий в соответствии с распределением просмотренных айтемов для этого юзера;\n",
    "а плохим айтемом будет просто любой другой случайный айтем*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a81e69e-fab3-4d82-9177-35bc4029cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вектор фичей юзера: (1024, 16)\n",
      "вектор взаимодействий юзера с айтемами: (1024, 6897)\n",
      "вектор 'хорошего' айтема: (1024, 9841)\n",
      "вектор 'плохого' айтема: (1024, 9841)\n",
      "\n",
      "вектор фичей юзера: (1024, 16)\n",
      "вектор взаимодействий юзера с айтемами: (1024, 6897)\n"
     ]
    }
   ],
   "source": [
    "def generator(items, users, interactions, batch_size=1024):\n",
    "    while True:\n",
    "        uid_meta = []\n",
    "        uid_interaction = []\n",
    "        pos = []\n",
    "        neg = []\n",
    "        for _ in range(batch_size):\n",
    "            # берем рандомный uid\n",
    "            uid_i = randint(0, interactions.shape[0] - 1)\n",
    "            # id хорошего айтема\n",
    "            pos_i = np.random.choice(range(interactions.shape[1]), p=interactions[uid_i])\n",
    "            # id плохого айтема\n",
    "            neg_i = np.random.choice(range(interactions.shape[1]))\n",
    "            # фичи юзера\n",
    "            uid_meta.append(users.iloc[uid_i])\n",
    "            # вектор айтемов, с которыми юзер взаимодействовал\n",
    "            uid_interaction.append(interactions_vec[uid_i])\n",
    "            # фичи хорошего айтема\n",
    "            pos.append(items.iloc[pos_i])\n",
    "            # фичи плохого айтема\n",
    "            neg.append(items.iloc[neg_i])\n",
    "\n",
    "        yield [np.array(uid_meta), np.array(uid_interaction), np.array(pos), np.array(neg)], [\n",
    "            np.array(uid_meta),\n",
    "            np.array(uid_interaction),\n",
    "        ]\n",
    "\n",
    "\n",
    "# инициализируем генератор\n",
    "gen = generator(\n",
    "    items=items_ohe_df.drop([\"item_id\"], axis=1),\n",
    "    users=users_ohe_df.drop([\"user_id\"], axis=1),\n",
    "    interactions=interactions_vec,\n",
    ")\n",
    "\n",
    "ret = next(gen)\n",
    "\n",
    "\n",
    "print(f\"вектор фичей юзера: {ret[0][0].shape}\")\n",
    "print(f\"вектор взаимодействий юзера с айтемами: {ret[0][1].shape}\")\n",
    "print(f\"вектор 'хорошего' айтема: {ret[0][2].shape}\")\n",
    "print(f\"вектор 'плохого' айтема: {ret[0][3].shape}\")\n",
    "print()\n",
    "print(f\"вектор фичей юзера: {ret[1][0].shape}\")\n",
    "print(f\"вектор взаимодействий юзера с айтемами: {ret[1][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b046b443-8309-4738-93f1-84b9cdb05bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2d7fd21-c239-4418-8736-d67b4b86a179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FACTORS: 128\n",
      "ITEM_MODEL_SHAPE: (9841,)\n",
      "USER_META_MODEL_SHAPE: (16,)\n",
      "USER_INTERACTION_MODEL_SHAPE: (6897,)\n"
     ]
    }
   ],
   "source": [
    "N_FACTORS = 128\n",
    "\n",
    "# в датасетах есть столбец user_id/item_id, помним, что он не является фичей для обучения!\n",
    "ITEM_MODEL_SHAPE = (items_ohe_df.drop([\"item_id\"], axis=1).shape[1],)\n",
    "USER_META_MODEL_SHAPE = (users_ohe_df.drop([\"user_id\"], axis=1).shape[1],)\n",
    "\n",
    "USER_INTERACTION_MODEL_SHAPE = (interactions_vec.shape[1],)\n",
    "\n",
    "print(f\"N_FACTORS: {N_FACTORS}\")\n",
    "print(f\"ITEM_MODEL_SHAPE: {ITEM_MODEL_SHAPE}\")\n",
    "print(f\"USER_META_MODEL_SHAPE: {USER_META_MODEL_SHAPE}\")\n",
    "print(f\"USER_INTERACTION_MODEL_SHAPE: {USER_INTERACTION_MODEL_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89d5b69a-091a-4d9b-854b-5d6ddc7d4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_model(n_factors=N_FACTORS):\n",
    "    # входной слой\n",
    "    inp = keras.layers.Input(shape=ITEM_MODEL_SHAPE)\n",
    "\n",
    "    # полносвязный слой\n",
    "    layer_1 = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"elu\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(inp)\n",
    "\n",
    "    # делаем residual connection - складываем два слоя,\n",
    "    # чтобы градиенты не затухали во время обучения\n",
    "    layer_2 = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"elu\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(layer_1)\n",
    "\n",
    "    add = keras.layers.Add()([layer_1, layer_2])\n",
    "\n",
    "    # выходной слой\n",
    "    out = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"linear\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(add)\n",
    "\n",
    "    return keras.models.Model(inp, out)\n",
    "\n",
    "\n",
    "def user_model(n_factors=N_FACTORS):\n",
    "    # входной слой для вектора фичей юзера (из users_ohe_df)\n",
    "    inp_meta = keras.layers.Input(shape=USER_META_MODEL_SHAPE)\n",
    "    # входной слой для вектора просмотров (из iteractions_vec)\n",
    "    inp_interaction = keras.layers.Input(shape=USER_INTERACTION_MODEL_SHAPE)\n",
    "\n",
    "    # полносвязный слой\n",
    "    layer_1_meta = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"elu\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(inp_meta)\n",
    "\n",
    "    layer_1_interaction = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"elu\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(inp_interaction)\n",
    "\n",
    "    # делаем residual connection - складываем два слоя,\n",
    "    # чтобы градиенты не затухали во время обучения\n",
    "    layer_2_meta = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"elu\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(layer_1_meta)\n",
    "\n",
    "    add = keras.layers.Add()([layer_1_meta, layer_2_meta])\n",
    "\n",
    "    # конкатенируем вектор фичей с вектором просмотров\n",
    "    concat_meta_interaction = keras.layers.Concatenate()([add, layer_1_interaction])\n",
    "\n",
    "    # выходной слой\n",
    "    out = keras.layers.Dense(\n",
    "        N_FACTORS,\n",
    "        activation=\"linear\",\n",
    "        use_bias=False,\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "        activity_regularizer=keras.regularizers.l2(l2=1e-6),\n",
    "    )(concat_meta_interaction)\n",
    "\n",
    "    return keras.models.Model([inp_meta, inp_interaction], out)\n",
    "\n",
    "\n",
    "# инициализируем модели юзера и айтема\n",
    "i2v = item_model()\n",
    "u2v = user_model()\n",
    "\n",
    "# вход для вектора фичей юзера (из users_ohe_df)\n",
    "ancor_meta_in = keras.layers.Input(shape=USER_META_MODEL_SHAPE)\n",
    "# вход для вектора просмотра юзера (из interactions_vec)\n",
    "ancor_interaction_in = keras.layers.Input(shape=USER_INTERACTION_MODEL_SHAPE)\n",
    "\n",
    "# вход для вектора \"хорошего\" айтема\n",
    "pos_in = keras.layers.Input(shape=ITEM_MODEL_SHAPE)\n",
    "# вход для вектора \"плохого\" айтема\n",
    "neg_in = keras.layers.Input(shape=ITEM_MODEL_SHAPE)\n",
    "\n",
    "# получаем вектор юзера\n",
    "ancor = u2v([ancor_meta_in, ancor_interaction_in])\n",
    "# получаем вектор \"хорошего\" айтема\n",
    "pos = i2v(pos_in)\n",
    "# получаем вектор \"плохого\" айтема\n",
    "neg = i2v(neg_in)\n",
    "\n",
    "# конкатенируем полученные векторы\n",
    "res = keras.layers.Concatenate(name=\"concat_ancor_pos_neg\")([ancor, pos, neg])\n",
    "\n",
    "# собираем модель\n",
    "model = keras.models.Model([ancor_meta_in, ancor_interaction_in, pos_in, neg_in], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99c2f4cf-f371-46d0-be84-345c2111bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"recsys_resnet_linear\"\n",
    "\n",
    "# логируем процесс обучения в тензорборд\n",
    "t_board = keras.callbacks.TensorBoard(log_dir=f\"runs/{model_name}\")\n",
    "\n",
    "# уменьшаем learning_rate, если лосс долго не уменьшается (в течение двух эпох)\n",
    "decay = keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=2, factor=0.8, verbose=1)\n",
    "\n",
    "# сохраняем модель после каждой эпохи, если лосс уменьшился\n",
    "check = keras.callbacks.ModelCheckpoint(filepath=model_name + \"/epoch{epoch}-{loss:.2f}.h5\", monitor=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f29af2d-4c9e-475e-9b5f-316d91efbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем модель, используем оптимайзер Adam и triplet loss\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=triplet_loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7460bbc4-a09a-4be9-b0fc-85f51fcd8356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 9841)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          1259648     ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          16384       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 128)          0           ['dense_7[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          16384       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,292,416\n",
      "Trainable params: 1,292,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          2048        ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          16384       ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 6897)]       0           []                               \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 128)          0           ['dense_10[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          882816      ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['add_3[0][0]',                  \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          32768       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 934,016\n",
      "Trainable params: 934,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 6897)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 9841)]       0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 9841)]       0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 128)          934016      ['input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          1292416     ['input_6[0][0]',                \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " concat_ancor_pos_neg (Concaten  (None, 384)         0           ['model_1[0][0]',                \n",
      " ate)                                                             'model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,226,432\n",
      "Trainable params: 2,226,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# модель айтема\n",
    "item_model().summary()\n",
    "# модель юзера\n",
    "user_model().summary()\n",
    "# общая модель\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06815d76-78fe-432f-961d-39887622102d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b0fe2e4-1c0b-44b6-ad4f-29b2652c3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 15:30:41.584112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 32s 315ms/step - loss: 0.5300 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 30s 307ms/step - loss: 0.3407 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 30s 307ms/step - loss: 0.3104 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 31s 318ms/step - loss: 0.2638 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 32s 327ms/step - loss: 0.2469 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.2342 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 33s 337ms/step - loss: 0.2121 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.2034 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 34s 348ms/step - loss: 0.1910 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 0.1846 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.1766 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 35s 351ms/step - loss: 0.1805 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1801\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.1801 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 33s 335ms/step - loss: 0.1608 - lr: 8.0000e-04\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.1591 - lr: 8.0000e-04\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.1522 - lr: 8.0000e-04\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.1583 - lr: 8.0000e-04\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.1513 - lr: 8.0000e-04\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 34s 347ms/step - loss: 0.1562 - lr: 8.0000e-04\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1515\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.1515 - lr: 8.0000e-04\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 34s 344ms/step - loss: 0.1474 - lr: 6.4000e-04\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 0.1463 - lr: 6.4000e-04\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 34s 344ms/step - loss: 0.1517 - lr: 6.4000e-04\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1465\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "100/100 [==============================] - 32s 327ms/step - loss: 0.1465 - lr: 6.4000e-04\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 34s 345ms/step - loss: 0.1440 - lr: 5.1200e-04\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 32s 328ms/step - loss: 0.1456 - lr: 5.1200e-04\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 33s 335ms/step - loss: 0.1253 - lr: 5.1200e-04\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 35s 358ms/step - loss: 0.1427 - lr: 5.1200e-04\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1338\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "100/100 [==============================] - 32s 328ms/step - loss: 0.1338 - lr: 5.1200e-04\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 0.1301 - lr: 4.0960e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efaa2c83430>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# начинаем обучение, не забывая дропнуть столбцы item_id и user_id\n",
    "# из датафреймов при инициализации генератора.\n",
    "\n",
    "# batch_size можно (и лучше) поставить побольше, если вы не органичены в ресурсах\n",
    "\n",
    "model.fit(\n",
    "    generator(\n",
    "        items=items_ohe_df.drop([\"item_id\"], axis=1),\n",
    "        users=users_ohe_df.drop([\"user_id\"], axis=1),\n",
    "        interactions=interactions_vec,\n",
    "        batch_size=64,\n",
    "    ),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    initial_epoch=0,\n",
    "    callbacks=[decay, t_board, check],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156387f0-f2a7-42a0-b756-80e0d97ac6c9",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d663cb7-fb6d-4fbb-b728-c1e71962d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем рандомного юзера и айтем\n",
    "rand_uid = np.random.choice(list(users_ohe_df.index))\n",
    "rand_iid = np.random.choice(list(items_ohe_df.index))\n",
    "k_recos = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fac39ca1-480a-4a33-accf-80ee08ade350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9532614]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем фичи юзера и вектор его просмотров айтемов\n",
    "user_meta_feats = users_ohe_df.drop([\"user_id\"], axis=1).iloc[rand_uid]\n",
    "user_interaction_vec = interactions_vec[rand_uid]\n",
    "# получаем фичи айтема\n",
    "item_feats = items_ohe_df.drop([\"item_id\"], axis=1).iloc[rand_iid]\n",
    "\n",
    "# получаем вектор юзера\n",
    "user_vec = u2v.predict([np.array(user_meta_feats).reshape(1, -1), np.array(user_interaction_vec).reshape(1, -1)])\n",
    "# и вектор айтема\n",
    "item_vec = i2v.predict(np.array(item_feats).reshape(1, -1))\n",
    "\n",
    "# считаем расстояние между вектором юзера и вектором айтема\n",
    "ED(user_vec, item_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c1d35-f41e-46b4-a9ee-338f0ec8c6b6",
   "metadata": {},
   "source": [
    "## Готовим на прод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1189ba-cca4-4695-93f1-bec0cef729d9",
   "metadata": {},
   "source": [
    "Подготовим лист популярного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed917026-494c-48c3-9257-9cfb70d4a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_popular = \"../models/pickle_data/popular.pickle\"\n",
    "loaded_popular = pickle.load(open(name_popular, \"rb\"))\n",
    "data_for_predict = Dataset.construct(interactions.df)\n",
    "max_k = len(kion_data[\"items\"][\"item_id\"].unique())\n",
    "sample_popular_user = data_for_predict.user_id_map.external_ids[0]\n",
    "popular_list = list(\n",
    "    loaded_popular.recommend(dataset=data_for_predict, users=[0], k=max_k, filter_viewed=False)[\"item_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d21ecc-890c-42a1-9ffc-42b8625d90e1",
   "metadata": {},
   "source": [
    "Остальные штучки для предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fff1c3d-82d6-48b5-9df8-995e8bb5abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 798us/step\n"
     ]
    }
   ],
   "source": [
    "# получаем фичи всех айтемов\n",
    "items_feats = items_ohe_df.drop([\"item_id\"], axis=1).to_numpy()\n",
    "# получаем векторы всех айтемов\n",
    "items_vecs = i2v.predict(items_feats)\n",
    "# список юзеров в dssm\n",
    "users_dssm = list(user_id_to_uid.keys())\n",
    "# users features\n",
    "users_meta_feats = users_ohe_df.drop([\"user_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc24a00-89c9-4c94-8202-2a8b73ed080d",
   "metadata": {},
   "source": [
    "Рядом лежит класс dssmmodel.py, который мы заиспользуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39fd2ff3-e430-4609-8f9b-c3829c97fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssm_model = DSSMModel(\n",
    "    items_vecs=items_vecs,\n",
    "    users_dssm=users_dssm,\n",
    "    users_meta_feats=users_meta_feats,\n",
    "    user_id_to_uid=user_id_to_uid,\n",
    "    interactions_vec=interactions_vec,\n",
    "    u2v=u2v,\n",
    "    iid_to_item_id=iid_to_item_id,\n",
    "    popular_list=popular_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9f1ba-0442-4861-a15a-1ebd5b6139cf",
   "metadata": {},
   "source": [
    "### Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4ec145f-bbe0-4f51-8d75-ab8d859d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dssm = \"../models/pickle_data/dssm.pickle\"\n",
    "pickle.dump(dssm_model, open(name_dssm, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf09b97-7fde-4544-871b-1668ef74e1de",
   "metadata": {},
   "source": [
    "## Проверка работоспособности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ded5350-e93d-40f4-9b99-0e60c839f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dssm = \"../models/pickle_data/dssm.pickle\"\n",
    "dssm_loaded = pickle.load(open(name_dssm, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00dca821-9c7c-4839-9ad9-34c98d192028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.2 ms ± 1.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "dssm_loaded.recommend(5324, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f6cff-7a69-4707-8ae7-d1ac4e62a373",
   "metadata": {},
   "source": [
    "Должно прокатить, но надо не забыть, что тут не все пользователи, для остальных -- классическое популярное будем возвращзать:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
